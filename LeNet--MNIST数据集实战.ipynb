{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "# tf.compat.v1.ConfigProto() 这是tensorflow2.0+版本的写法，这个方法的作用就是设置运行tensorflow代码的时候的一些配置，例如如何分配显存，是否打印日志等;所以它的参数都是　配置名称＝True/False(默认为False) 这种形式\n",
    "# gpu_options=tf.compat.v1.GPUOptions(allow_growth=True) 限制GPU资源的使用，此处allow_growth=True是动态分配显存，需要多少，申请多少，不是一成不变、而是一直变化\n",
    "# sess = tf.compat.v1.Session(config=config)　让这些配置生效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            multiple                  60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  48120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Conv2D(6,3),\n",
    "    keras.layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    keras.layers.ReLU(),\n",
    "    \n",
    "    keras.layers.Conv2D(16,3),\n",
    "    keras.layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    keras.layers.ReLU(),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(120,activation='relu'),\n",
    "    keras.layers.Dense(84,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "model.build(input_shape=(batch,28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = keras.losses.CategoricalCrossentropy() #损失函数交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss = keras.losses.CategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data('C:\\jupyter_workspace\\MNIST_npz\\mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255.\n",
    "    x = tf.reshape(x,[-1,28,28,1])\n",
    "    y = tf.one_hot(y,depth=10)\n",
    "    return x,y\n",
    "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data('C:\\jupyter_workspace\\MNIST_npz\\mnist.npz')\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_db = train_db.shuffle(10000)\n",
    "train_db = train_db.batch(128)\n",
    "train_db = train_db.map(preprocess)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.shuffle(10000)\n",
    "test_db = test_db.batch(128)\n",
    "test_db = test_db.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.3838 - accuracy: 0.8955\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0934 - accuracy: 0.9717\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0671 - accuracy: 0.9794\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0522 - accuracy: 0.9841\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0437 - accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0368 - accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0314 - accuracy: 0.9901\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0280 - accuracy: 0.9912\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0235 - accuracy: 0.9924\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0205 - accuracy: 0.9937 0s - loss:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15347133d90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_db,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.030116476118564606, 0.9902999997138977]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
